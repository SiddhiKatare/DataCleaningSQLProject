**Data Cleaning and Standardization Project**

**About**

This project focuses on enhancing data quality by cleaning and standardizing multiple datasets. The goal was to create a reliable and consistent dataset ready for analysis by standardizing date formats, breaking out addresses into distinct components (address, city, state), and eliminating duplicate records. Through this process, I demonstrated proficiency in data cleaning and database management, ultimately leading to improved data integrity and more efficient analytical processes.

**Key Technologies**

•	Python: For scripting and automation of data cleaning tasks.

•	Pandas: Utilized for data manipulation and preprocessing.

•	SQL: Employed for database management and executing complex queries.

•	Jupyter Notebook: For iterative development and visualization.

•	Excel: For initial data review and simple transformations.

**Project Highlights
**
•	Date Standardization: Unified date formats across the dataset to ensure consistency.

•	Address Breakdown: Split address data into separate columns for address, city, and state, enabling more granular analysis.

•	Duplicate Removal: Identified and removed duplicate records, leading to a more accurate and streamlined dataset.

**Outcomes**

The successful completion of this project resulted in a clean, standardized dataset, which greatly improved the accuracy and efficiency of subsequent data analysis tasks. This project highlights my skills in data cleaning, database management, and the use of key technologies in transforming raw data into a valuable resource.
